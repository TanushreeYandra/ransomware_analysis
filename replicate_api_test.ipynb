{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adb1093-feb4-4398-9b86-49a81eca55cc",
   "metadata": {},
   "source": [
    "# AI-Generated Data Using Replicate API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b13fe7-d3b7-43e9-bf3b-39f8c8d6793c",
   "metadata": {},
   "source": [
    "#### Installation\n",
    "\n",
    "Create Replicate account, check status of jobs etc on the Dashboard: https://replicate.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25895b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: replicate==0.15.5 in /Users/tanu/anaconda3/lib/python3.11/site-packages (0.15.5)\n",
      "Requirement already satisfied: packaging in /Users/tanu/anaconda3/lib/python3.11/site-packages (from replicate==0.15.5) (23.1)\n",
      "Requirement already satisfied: pydantic>1 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from replicate==0.15.5) (1.10.8)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from replicate==0.15.5) (0.25.1)\n",
      "Requirement already satisfied: anyio in /Users/tanu/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate==0.15.5) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/tanu/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate==0.15.5) (2023.11.17)\n",
      "Requirement already satisfied: httpcore in /Users/tanu/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate==0.15.5) (1.0.1)\n",
      "Requirement already satisfied: idna in /Users/tanu/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate==0.15.5) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/tanu/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate==0.15.5) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from pydantic>1->replicate==0.15.5) (4.7.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.21.0->replicate==0.15.5) (0.14.0)\n",
      "Requirement already satisfied: ipython-autotime in /Users/tanu/anaconda3/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: ipython in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython-autotime) (8.15.0)\n",
      "Requirement already satisfied: backcall in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (5.7.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/tanu/anaconda3/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/tanu/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/tanu/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/tanu/anaconda3/lib/python3.11/site-packages (from stack-data->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/tanu/anaconda3/lib/python3.11/site-packages (from stack-data->ipython->ipython-autotime) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/tanu/anaconda3/lib/python3.11/site-packages (from stack-data->ipython->ipython-autotime) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/tanu/anaconda3/lib/python3.11/site-packages (from asttokens->stack-data->ipython->ipython-autotime) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install replicate==0.15.5\n",
    "!pip install ipython-autotime\n",
    "# run this command in terminal before launching this notebook\n",
    "!export REPLICATE_API_TOKEN=\"r8_QwJg65myol6cBI3v8zJ5bxx27MLw19Y32vsPv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "118ef80b-3e9d-416d-89fb-7addb2eb8b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 87.7 µs (started: 2024-02-07 10:47:21 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "from IPython.display import Image, Audio\n",
    "import random\n",
    "import pandas as pd\n",
    "import re, json\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309d2ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.3 ms (started: 2024-02-07 10:47:21 -08:00)\n"
     ]
    }
   ],
   "source": [
    "replicate = replicate.Client(api_token=\"r8_QwJg65myol6cBI3v8zJ5bxx27MLw19Y32vsPv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8280eaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 96.3 µs (started: 2024-02-07 10:47:21 -08:00)\n"
     ]
    }
   ],
   "source": [
    "num=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3499c",
   "metadata": {},
   "source": [
    "## Audio Generation\n",
    "\n",
    "Examples: https://replicate.com/collections/audio-generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47edfa5f",
   "metadata": {},
   "source": [
    "API Reference: https://replicate.com/meta/musicgen/api?tab=node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff89a53",
   "metadata": {},
   "source": [
    "### 1. Generate .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cebf36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8min 14s (started: 2024-02-06 17:59:54 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"meta/musicgen:7a76a8258b23fae65c5a22debb8841d1d7e816b75c2f24218cd2bd8573787906\"\n",
    "\n",
    "for i in range(10):\n",
    "    prompt = \"Edo25 major g melodies that sound triumphant and cinematic. \\\n",
    "    Leading up to a crescendo that resolves in a 9th harmonic\"\n",
    "    duration = random.randint(5, 30)\n",
    "    audio_output = replicate.run(version,\n",
    "      input={\n",
    "        \"seed\": 3442726813,\n",
    "        \"top_k\": 250,\n",
    "        \"top_p\": 0,\n",
    "        \"prompt\": prompt,\n",
    "        \"duration\": duration,\n",
    "        \"temperature\": 1,\n",
    "        \"continuation\": False,\n",
    "        \"model_version\": \"large\",\n",
    "        \"output_format\": \"wav\",\n",
    "        \"continuation_end\": 9,\n",
    "        \"continuation_start\": 7,\n",
    "        \"normalization_strategy\": \"peak\",\n",
    "        \"classifier_free_guidance\": 3\n",
    "      }\n",
    "    )\n",
    "    Audio(audio_output, rate=22050)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.wav'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(Audio(audio_output, rate=22050).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2a1e8",
   "metadata": {},
   "source": [
    "### 2. Generate .mp3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "874dedfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6min 2s (started: 2024-02-07 11:47:42 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"meta/musicgen:7a76a8258b23fae65c5a22debb8841d1d7e816b75c2f24218cd2bd8573787906\"\n",
    "\n",
    "for i in range(20):\n",
    "    prompt = \"Edo25 major g melodies that sound triumphant and cinematic. \\\n",
    "    Leading up to a crescendo that resolves in a 9th harmonic\"\n",
    "    duration = random.randint(5, 30)\n",
    "    audio_output = replicate.run(version,\n",
    "      input={\n",
    "        \"seed\": 3442726813,\n",
    "        \"top_k\": 250,\n",
    "        \"top_p\": 0,\n",
    "        \"prompt\": prompt,\n",
    "        \"duration\": duration,\n",
    "        \"temperature\": 1,\n",
    "        \"continuation\": False,\n",
    "        \"model_version\": \"large\",\n",
    "        \"output_format\": \"wav\",\n",
    "        \"continuation_end\": 9,\n",
    "        \"continuation_start\": 7,\n",
    "        \"normalization_strategy\": \"peak\",\n",
    "        \"classifier_free_guidance\": 3\n",
    "      }\n",
    "    )\n",
    "    Audio(audio_output, rate=22050)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.mp3'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(Audio(audio_output, rate=22050).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4a355",
   "metadata": {},
   "source": [
    "### 3. Generate .aac files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d94be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8min 6s (started: 2024-02-06 18:24:32 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"meta/musicgen:7a76a8258b23fae65c5a22debb8841d1d7e816b75c2f24218cd2bd8573787906\"\n",
    "\n",
    "for i in range(10):\n",
    "    prompt = \"Edo25 major g melodies that sound triumphant and cinematic. \\\n",
    "    Leading up to a crescendo that resolves in a 9th harmonic\"\n",
    "    duration = random.randint(5, 30)\n",
    "    audio_output = replicate.run(version,\n",
    "      input={\n",
    "        \"seed\": 3442726813,\n",
    "        \"top_k\": 250,\n",
    "        \"top_p\": 0,\n",
    "        \"prompt\": prompt,\n",
    "        \"duration\": duration,\n",
    "        \"temperature\": 1,\n",
    "        \"continuation\": False,\n",
    "        \"model_version\": \"large\",\n",
    "        \"output_format\": \"wav\",\n",
    "        \"continuation_end\": 9,\n",
    "        \"continuation_start\": 7,\n",
    "        \"normalization_strategy\": \"peak\",\n",
    "        \"classifier_free_guidance\": 3\n",
    "      }\n",
    "    )\n",
    "    Audio(audio_output, rate=22050)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.aac'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(Audio(audio_output, rate=22050).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd5fdf4",
   "metadata": {},
   "source": [
    "### 4. Generate .flac files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d52ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11min 45s (started: 2024-02-06 18:32:39 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"meta/musicgen:7a76a8258b23fae65c5a22debb8841d1d7e816b75c2f24218cd2bd8573787906\"\n",
    "\n",
    "for i in range(10):\n",
    "    prompt = \"Edo25 major g melodies that sound triumphant and cinematic. \\\n",
    "    Leading up to a crescendo that resolves in a 9th harmonic\"\n",
    "    duration = random.randint(5, 30)\n",
    "    audio_output = replicate.run(version,\n",
    "      input={\n",
    "        \"seed\": 3442726813,\n",
    "        \"top_k\": 250,\n",
    "        \"top_p\": 0,\n",
    "        \"prompt\": prompt,\n",
    "        \"duration\": duration,\n",
    "        \"temperature\": 1,\n",
    "        \"continuation\": False,\n",
    "        \"model_version\": \"large\",\n",
    "        \"output_format\": \"wav\",\n",
    "        \"continuation_end\": 9,\n",
    "        \"continuation_start\": 7,\n",
    "        \"normalization_strategy\": \"peak\",\n",
    "        \"classifier_free_guidance\": 3\n",
    "      }\n",
    "    )\n",
    "    Audio(audio_output, rate=22050)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.flac'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(Audio(audio_output, rate=22050).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4a83f",
   "metadata": {},
   "source": [
    "## Image Generation Using Stable Diffusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664cde7",
   "metadata": {},
   "source": [
    "#### Stable Diffusion 1.5\n",
    "\n",
    "An earlier version of stable diffusion trained on smaller images (512*512). Generation times are much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cff8d5",
   "metadata": {},
   "source": [
    "### 1. Generate .jpg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3329a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 s (started: 2024-02-07 14:03:42 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\"\n",
    "\n",
    "for i in range(80):\n",
    "    query = \"Photo of a storm in a beautiful countryside\"\n",
    "    image_url = replicate.run(version,\n",
    "                              input={\"prompt\": query}\n",
    "                             )[0]\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.jpg'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(requests.get(image_url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22658e",
   "metadata": {},
   "source": [
    "### 2. Generate .png files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84dce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 9s (started: 2024-02-06 18:51:33 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\"\n",
    "\n",
    "for i in range(50):\n",
    "    query = \"Photo of a waterfall next to a river\"\n",
    "    image_url = replicate.run(version,\n",
    "                              input={\"prompt\": query}\n",
    "                             )[0]\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.png'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(requests.get(image_url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146978e",
   "metadata": {},
   "source": [
    "### 3. Generate .gif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e37dc898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 38s (started: 2024-02-06 18:55:43 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\"\n",
    "\n",
    "for i in range(20):\n",
    "    query = \"Photo of a hospital\"\n",
    "    image_url = replicate.run(version,\n",
    "                              input={\"prompt\": query}\n",
    "                             )[0]\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.gif'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(requests.get(image_url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda1879",
   "metadata": {},
   "source": [
    "### 4. Generate .bmp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d9a3195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.8 s (started: 2024-02-06 18:57:21 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\"\n",
    "\n",
    "for i in range(10):\n",
    "    query = \"Photo of a cheetah on a tree\"\n",
    "    image_url = replicate.run(version,\n",
    "                              input={\"prompt\": query}\n",
    "                             )[0]\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.bmp'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(requests.get(image_url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cea544",
   "metadata": {},
   "source": [
    "### 5. Generate .webp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a281456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 49.7 s (started: 2024-02-06 18:58:10 -08:00)\n"
     ]
    }
   ],
   "source": [
    "version = \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\"\n",
    "\n",
    "for i in range(10):\n",
    "    query = \"Photo of a family\"\n",
    "    image_url = replicate.run(version,\n",
    "                              input={\"prompt\": query}\n",
    "                             )[0]\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.webp'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(requests.get(image_url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfae10",
   "metadata": {},
   "source": [
    "## Tabular Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33de65e",
   "metadata": {},
   "source": [
    "### 1. Generate .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ed6b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 18s (started: 2024-02-07 14:19:22 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(70):\n",
    "    model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "    version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "        input={\"prompt\":\"Generate 10 objects where each object has the following JSON structure\\ \\\"{\\\"A\\\": \\\n",
    "        \\\"Value\\\",\\\"B\\\": \\\"Value\\\",\\\"C\\\": \\\"Value\\\",\\\"D\\\": \\\"Value\\\",\\\"E\\\": \\\"Value\\\",\\\"F\\\": \\\"Value\\\"}\\\n",
    "        Replace \\\"Value\\\" with a random string of 10-20 characters containing alphabets and numbers that \\\n",
    "        is enclosed in double quotes\", \"max_new_tokens\": 10000})\n",
    "\n",
    "    predictions = replicate.predictions.list()\n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    \n",
    "    # Extract JSON-like objects using regular expressions\n",
    "    json_objects = re.findall(r'{[^}]+}', text_output)\n",
    "\n",
    "    # Replace newline characters and make the JSON-like objects more compact\n",
    "    json_objects_compact = [json_obj.replace('\\n', '').replace('\\r', '') for json_obj in json_objects]\n",
    "\n",
    "    # Replace single backslashes with double backslashes\n",
    "    json_objects_escaped = [json_obj.replace('\\\\', '\\\\\\\\') for json_obj in json_objects_compact]\n",
    "\n",
    "    # Convert string representations of dictionaries to actual dictionaries\n",
    "    dict_objects = [json.loads(json_obj) for json_obj in json_objects_escaped]\n",
    "\n",
    "    # Create a DataFrame from the dictionaries\n",
    "    df = pd.DataFrame(dict_objects)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.csv'\n",
    "\n",
    "    df.to_csv(f'''files_dataset/original_2/{file_name}''', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a8353",
   "metadata": {},
   "source": [
    "### 2. Generate .xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f54b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5min 4s (started: 2024-02-06 19:17:10 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(40):\n",
    "    model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "    version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "        input={\"prompt\":\"Generate 10 objects where each object has the following JSON structure\\ \\\"{\\\"A\\\": \\\n",
    "        \\\"Value\\\",\\\"B\\\": \\\"Value\\\",\\\"C\\\": \\\"Value\\\",\\\"D\\\": \\\"Value\\\",\\\"E\\\": \\\"Value\\\",\\\"F\\\": \\\"Value\\\"}\\\n",
    "        Replace \\\"Value\\\" with a random string of 10-20 characters containing alphabets and numbers that \\\n",
    "        is enclosed in double quotes\", \"max_new_tokens\": 10000})\n",
    "\n",
    "    predictions = replicate.predictions.list()\n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    \n",
    "    # Extract JSON-like objects using regular expressions\n",
    "    json_objects = re.findall(r'{[^}]+}', text_output)\n",
    "\n",
    "    # Replace newline characters and make the JSON-like objects more compact\n",
    "    json_objects_compact = [json_obj.replace('\\n', '').replace('\\r', '') for json_obj in json_objects]\n",
    "\n",
    "    # Replace single backslashes with double backslashes\n",
    "    json_objects_escaped = [json_obj.replace('\\\\', '\\\\\\\\') for json_obj in json_objects_compact]\n",
    "\n",
    "    # Convert string representations of dictionaries to actual dictionaries\n",
    "    dict_objects = [json.loads(json_obj) for json_obj in json_objects_escaped]\n",
    "\n",
    "    # Create a DataFrame from the dictionaries\n",
    "    df = pd.DataFrame(dict_objects)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.xlsx'\n",
    "\n",
    "    df.to_excel(f'''files_dataset/original_2/{file_name}''', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58785cca",
   "metadata": {},
   "source": [
    "### 3. Generate .tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d05da136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.5 s (started: 2024-02-07 14:11:49 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(20):\n",
    "    model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "    version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "        input={\"prompt\":\"Generate 10 objects where each object has the following JSON structure\\ \\\"{\\\"A\\\": \\\n",
    "        \\\"Value\\\",\\\"B\\\": \\\"Value\\\",\\\"C\\\": \\\"Value\\\",\\\"D\\\": \\\"Value\\\",\\\"E\\\": \\\"Value\\\",\\\"F\\\": \\\"Value\\\"}\\\n",
    "        Replace \\\"Value\\\" with a random string of 10-20 characters containing alphabets and numbers that \\\n",
    "        is enclosed in double quotes\", \"max_new_tokens\": 10000})\n",
    "\n",
    "    predictions = replicate.predictions.list()\n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    \n",
    "    # Extract JSON-like objects using regular expressions\n",
    "    json_objects = re.findall(r'{[^}]+}', text_output)\n",
    "\n",
    "    # Replace newline characters and make the JSON-like objects more compact\n",
    "    json_objects_compact = [json_obj.replace('\\n', '').replace('\\r', '') for json_obj in json_objects]\n",
    "\n",
    "    # Replace single backslashes with double backslashes\n",
    "    json_objects_escaped = [json_obj.replace('\\\\', '\\\\\\\\') for json_obj in json_objects_compact]\n",
    "\n",
    "    # Convert string representations of dictionaries to actual dictionaries\n",
    "    dict_objects = [json.loads(json_obj) for json_obj in json_objects_escaped]\n",
    "\n",
    "    # Create a DataFrame from the dictionaries\n",
    "    df = pd.DataFrame(dict_objects)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.tsv'\n",
    "\n",
    "    df.to_csv(f'''files_dataset/original_2/{file_name}''', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913a6db",
   "metadata": {},
   "source": [
    "### 4. Generate .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdd0fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.1 s (started: 2024-02-06 19:32:45 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(20):\n",
    "    model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "    version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "        input={\"prompt\":\"Generate 10 objects where each object has the following JSON structure\\ \\\"{\\\"A\\\": \\\n",
    "        \\\"Value\\\",\\\"B\\\": \\\"Value\\\",\\\"C\\\": \\\"Value\\\",\\\"D\\\": \\\"Value\\\",\\\"E\\\": \\\"Value\\\",\\\"F\\\": \\\"Value\\\"}\\\n",
    "        Replace \\\"Value\\\" with a random string of 10-20 characters containing alphabets and numbers that \\\n",
    "        is enclosed in double quotes\", \"max_new_tokens\": 10000})\n",
    "\n",
    "    predictions = replicate.predictions.list()\n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    \n",
    "    # Extract JSON-like objects using regular expressions\n",
    "    json_objects = re.findall(r'{[^}]+}', text_output)\n",
    "\n",
    "    # Replace newline characters and make the JSON-like objects more compact\n",
    "    json_objects_compact = [json_obj.replace('\\n', '').replace('\\r', '') for json_obj in json_objects]\n",
    "\n",
    "    # Replace single backslashes with double backslashes\n",
    "    json_objects_escaped = [json_obj.replace('\\\\', '\\\\\\\\') for json_obj in json_objects_compact]\n",
    "\n",
    "    # Convert string representations of dictionaries to actual dictionaries\n",
    "    dict_objects = [json.loads(json_obj) for json_obj in json_objects_escaped]\n",
    "\n",
    "    # Create a DataFrame from the dictionaries\n",
    "    df = pd.DataFrame(dict_objects)\n",
    "    \n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.json'\n",
    "\n",
    "    df.to_json(f'''files_dataset/original_2/{file_name}''', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b5399-d0d3-464e-a15b-a7fd2ca28e28",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161d433-34c3-441f-a8d8-369e4a24758e",
   "metadata": {},
   "source": [
    "Replicate supports a large number of language models, check them out here: https://replicate.com/collections/language-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4b288",
   "metadata": {},
   "source": [
    "### 1. Generate .pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7089d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.7 ms (started: 2024-02-06 19:33:12 -08:00)\n"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be3de363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 11s (started: 2024-02-06 20:16:08 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(200):\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "    input={\"prompt\":\"Summarize the discovery of atoms\", \"max_new_tokens\": 1000})\n",
    "    predictions = replicate.predictions.list()\n",
    "    \n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.pdf'\n",
    "    \n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size = 12)\n",
    "    lines = text_output.split('\\n')\n",
    "    max_line_width = 180\n",
    "    \n",
    "    for line in lines:\n",
    "        while pdf.get_string_width(line) > max_line_width:\n",
    "            # If the line width exceeds the maximum, split it\n",
    "            index = 0\n",
    "            while pdf.get_string_width(line[:index + 1]) <= max_line_width and index < len(line):\n",
    "                index += 1\n",
    "\n",
    "            # Add the part of the line that fits into the cell\n",
    "            pdf.cell(max_line_width, 10, txt=line[:index].strip(), ln=True)\n",
    "            # Remove the processed part from the line\n",
    "            line = line[index:]\n",
    "        # Add the remaining part of the line\n",
    "        pdf.cell(max_line_width, 10, txt=line.strip(), ln=True)\n",
    "    \n",
    "    pdf.output(f'''files_dataset/original_2/{file_name}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacbfe56",
   "metadata": {},
   "source": [
    "### 2. Generate .html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1cbf0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.7 s (started: 2024-02-07 14:11:15 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(150):\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "    input={\"prompt\":\"Summarize the invention of light bulb\", \"max_new_tokens\": 1000})\n",
    "    predictions = replicate.predictions.list()\n",
    "    \n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.html'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'w') as f:\n",
    "        f.write(text_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9debf",
   "metadata": {},
   "source": [
    "### 3. Generate .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad95b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 14s (started: 2024-02-07 14:04:40 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(80):\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "    input={\"prompt\":\"Summarize the history of United Kingdom\", \"max_new_tokens\": 1000})\n",
    "    predictions = replicate.predictions.list()\n",
    "    \n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.txt'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'w') as f:\n",
    "        f.write(text_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6d2aa",
   "metadata": {},
   "source": [
    "### 4. Generate .doc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "190ff6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 59.8 s (started: 2024-02-07 14:05:54 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(50):\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "    input={\"prompt\":\"Summarize the history of China\", \"max_new_tokens\": 1000})\n",
    "    predictions = replicate.predictions.list()\n",
    "    \n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.doc'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'w') as f:\n",
    "        f.write(text_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca8f4e",
   "metadata": {},
   "source": [
    "### 5. Generate .docx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4efe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 101 ms (started: 2024-02-07 11:18:46 -08:00)\n"
     ]
    }
   ],
   "source": [
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd3d7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7min 36s (started: 2024-02-07 11:18:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(40):\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "    input={\"prompt\":\"Summarize the history of Van Gogh\", \"max_new_tokens\": 1000})\n",
    "    predictions = replicate.predictions.list()\n",
    "    \n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.docx'\n",
    "    \n",
    "    # Create a new Document\n",
    "    doc = Document()\n",
    "    # Add a paragraph with the text content\n",
    "    doc.add_paragraph(text_output)\n",
    "    # Save the Document to the specified file path\n",
    "    doc.save(f'''files_dataset/original_2/{file_name}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c092d5c",
   "metadata": {},
   "source": [
    "### 6. Generate .xml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e45108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 59.8 ms (started: 2024-02-07 11:33:15 -08:00)\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b0e3c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.7 s (started: 2024-02-07 14:06:54 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(20):\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "    input={\"prompt\":\"Summarize the history of valentine's day\", \"max_new_tokens\": 1000})\n",
    "    predictions = replicate.predictions.list()\n",
    "    \n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.xml'\n",
    "    \n",
    "    root = ET.Element(\"root\")\n",
    "    # Add a child element with the text content\n",
    "    child = ET.SubElement(root, \"text_content\")\n",
    "    child.text = text_output\n",
    "    # Create the XML tree\n",
    "    tree = ET.ElementTree(root)\n",
    "\n",
    "    # Save the XML tree to the specified file path\n",
    "    tree.write(f'''files_dataset/original_2/{file_name}''', encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5112cff",
   "metadata": {},
   "source": [
    "### 7. Generate .log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e1263f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 56.1 s (started: 2024-02-07 14:07:52 -08:00)\n"
     ]
    }
   ],
   "source": [
    "model = replicate.models.get(\"meta/llama-2-7b-chat\")\n",
    "version = model.versions.get(\"13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\")\n",
    "\n",
    "for i in range(10):\n",
    "    prediction = replicate.predictions.create(version=version,\n",
    "    input={\"prompt\":\"Summarize the history of Issac Newton\", \"max_new_tokens\": 1000})\n",
    "    predictions = replicate.predictions.list()\n",
    "    \n",
    "    while prediction.status != 'succeeded':\n",
    "        time.sleep(1)\n",
    "        prediction.reload()\n",
    "    text_output = ''.join(prediction.output)\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.log'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'w') as f:\n",
    "        f.write(text_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a92827-b960-4e1b-b71a-81c471f80bc7",
   "metadata": {},
   "source": [
    "## Video Generation\n",
    "\n",
    "TODO: Takes too long and generates outputs that are too short (few seconds long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2ad1f",
   "metadata": {},
   "source": [
    "### 1. Generate .mp4 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6048e469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 26s (started: 2024-02-07 14:08:48 -08:00)\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    \n",
    "    output = replicate.run(\n",
    "    model_version=\"cjwbw/damo-text-to-video:1e205ea73084bd17a0a3b43396e49ba0d6bc2e754e9283b2df49fad2dcf95755\",\n",
    "    input={\"prompt\": \"A baby eating a banana\"}\n",
    "    )\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.mp4'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(requests.get(output).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4d912",
   "metadata": {},
   "source": [
    "### 2. Generate .mov files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d864abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 7s (started: 2024-02-07 11:45:35 -08:00)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    output = replicate.run(\n",
    "    model_version=\"cjwbw/damo-text-to-video:1e205ea73084bd17a0a3b43396e49ba0d6bc2e754e9283b2df49fad2dcf95755\",\n",
    "    input={\"prompt\": \"A child blowing bubbles\"}\n",
    "    )\n",
    "    formatted_num = '{:03}'.format(num)\n",
    "    num = num+1\n",
    "    file_name = formatted_num + '.mov'\n",
    "\n",
    "    with open(f'''files_dataset/original_2/{file_name}''', 'wb') as f:\n",
    "        f.write(requests.get(output).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
